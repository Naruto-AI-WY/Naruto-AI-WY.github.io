<!DOCTYPE html>
<html lang="zh-cn">
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
  <title>数据读取与数据扩增 - Naruto&#39;s AI blog</title>
  <meta name="renderer" content="webkit" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>

<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />

<meta name="theme-color" content="#f8f5ec" />
<meta name="msapplication-navbutton-color" content="#f8f5ec">
<meta name="apple-mobile-web-app-capable" content="yes">
<meta name="apple-mobile-web-app-status-bar-style" content="#f8f5ec">


<meta name="author" content="Naruto" /><meta name="description" content="图像读取 在Python中有很多库可以完成数据读取的操作，比较常见的有Pillow和OpenCV。
PyTorch载入图片后ToTensor解读（含PIL和OpenCV读取图片对比）
（1）Pillow Pillow是Python图像处理函式库(PIL）的一个分支。Pillow提供了常见的图像读取和处理的操作，而且可以与ipython notebook无缝集成，是应用比较广泛的库。
1 2 3 4 5  from PIL import Image # 导入Pillow库 # 读取图片 im =Image.open(cat.jpg&amp;#39;)   1 2 3 4 5  from PIL import Image, ImageFilter im = Image.open(&amp;#39;cat.jpg&amp;#39;) # 应用模糊滤镜: im2 = im.filter(ImageFilter.BLUR) im2.save(&amp;#39;blur.jpg&amp;#39;, &amp;#39;jpeg&amp;#39;)   1 2 3 4 5  from PIL import Image # 打开一个jpg图像文件，注意是当前路径: im = Image.open(&amp;#39;cat.jpg&amp;#39;) im.thumbnail((w//2, h//2)) im.save(&amp;#39;thumbnail.jpg&amp;#39;, &amp;#39;jpeg&amp;#39;)   Pillow的官方文档：https://pillow.readthedocs.io/en/stable/
（2）OpenCV OpenCV是一个跨平台的计算机视觉库，最早由Intel开源得来。OpenCV发展的非常早，拥有众多的计算机视觉、数字图像处理和机器视觉等功能。OpenCV在功能上比Pillow更加强大很多，学习成本也高很多。
1 2 3 4 5  import cv2 # 导入Opencv库 img = cv2.imread(&amp;#39;cat.jpg&amp;#39;) # Opencv默认颜色通道顺序是BRG，转换一下 img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)   1 2 3 4 5  import cv2 # 导入Opencv库 img = cv2.imread(&amp;#39;cat.jpg&amp;#39;) img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) # 转换为灰度图   1 2 3 4 5 6 7 8  import cv2 # 导入Opencv库 img = cv2.imread(&amp;#39;cat.jpg&amp;#39;) img =cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) # 转换为灰度图 # Canny边缘检测 edges = cv2.Canny(img, 30, 70) cv2.imwrite(&amp;#39;canny.jpg&amp;#39;, edges)   OpenCV包含了众多的图像处理的功能，OpenCV包含了你能想得到的只要与图像相关的操作。此外OpenCV还内置了很多的图像特征处理算法，如关键点检测、边缘检测和直线检测等。
OpenCV官网：https://opencv.org/
OpenCV Github：https://github.com/opencv/opencv
OpenCV 扩展算法库：https://github.com/opencv/opencv_contrib
数据扩增方法 数据扩增介绍 在深度学习中数据扩增方法非常重要，数据扩增可以增加训练集的样本，同时也可以有效缓解模型过拟合的情况，也可以给模型带来的更强的泛化能力。
常见的数据扩增方法 在常见的数据扩增方法中，一般会从图像颜色、尺寸、形态、空间和像素等角度进行变换。当然不同的数据扩增方法可以自由进行组合，得到更加丰富的数据扩增方法。
以torchvision为例，常见的数据扩增方法包括：
transforms.CenterCrop 对图片中心进行裁剪
transforms.ColorJitter 对图像颜色的对比度、饱和度和零度进行变换
transforms.FiveCrop 对图像四个角和中心进行裁剪得到五分图像
transforms.Grayscale 对图像进行灰度变换
transforms.Pad 使用固定值进行像素填充
transforms.RandomAffine 随机仿射变换
transforms.RandomCrop 随机区域裁剪
transforms.RandomHorizontalFlip 随机水平翻转
transforms.RandomRotation 随机旋转
transforms.RandomVerticalFlip 随机垂直翻转
常用的数据扩增库   torchvision
https://github.com/pytorch/vision
pytorch官方提供的数据扩增库，提供了基本的数据数据扩增方法，可以无缝与torch进行集成；但数据扩增方法种类较少，且速度中等；
  imgaug
https://github.com/aleju/imgaug
imgaug是常用的第三方数据扩增库，提供了多样的数据扩增方法，且组合起来非常方便，速度较快；
  albumentations
https://albumentations.readthedocs.io
是常用的第三方数据扩增库，提供了多样的数据扩增方法，对图像分类、语义分割、物体检测和关键点检测都支持，速度较快。
  Pytorch读取数据 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57  import os, sys, glob, shutil, json import cv2 from PIL import Image import numpy as np import torch from torch.utils.data.dataset import Dataset import torchvision.transforms as transforms class SVHNDataset(Dataset): def __init__(self, img_path, img_label, transform=None): # 重写Dataset的初始化方法，在初始化的时候将数据载入 self.img_path = img_path self.img_label = img_label if transform is not None: self.transform = transform else: self.transform = None def __getitem__(self, index): # 返回一行数据 img = Image.open(self.img_path[index]).convert(&amp;#39;RGB&amp;#39;) if self.transform is not None: img = self.transform(img) # 原始SVHN中类别10为数字0 lbl = np.array(self.img_label[index], dtype=np.int) lbl = list(lbl) &#43; (5 - len(lbl)) * [10] return img, torch.from_numpy(np.array(lbl[:5])) def __len__(self): #返回长度，数据总数 return len(self.img_path) train_path = glob.glob(&amp;#39;../input/train/*.png&amp;#39;) train_path.sort() train_json = json.load(open(&amp;#39;../input/train.json&amp;#39;)) train_label = [train_json[x][&amp;#39;label&amp;#39;] for x in train_json] data = SVHNDataset(train_path, train_label, # Compose方法将几种变换组合起来 transforms.Compose([ # 缩放到固定尺寸 transforms.Resize((64, 128)), # 随机颜色变换 transforms.ColorJitter(0.2, 0.2, 0.2), # 加入随机旋转 transforms.RandomRotation(5), # 将图片转换为pytorch 的tenstor，（C,H,W）的转换、PyTorch在做一般的深度学习图像处理任务时，先使用dataset类和dataloader类读入图片，在读入的时候需要做transform变换，其中transform一般都需要ToTensor()操作，将dataset类中__getitem__()方法内读入的PIL或CV的图像数据转换为torch.FloatTensor # transforms.ToTensor(), # 对图像像素进行归一化 # transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225]) ]))    Dataset：对数据集的封装，提供索引方式的对数据样本进行读取 DataLoder：对Dataset进行封装，提供批量读取的迭代读取  详细可阅读下面的文章
PyTorch实现自由的数据读取
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55  import os, sys, glob, shutil, json import cv2 from PIL import Image import numpy as np import torch from torch.utils.data.dataset import Dataset import torchvision.transforms as transforms class SVHNDataset(Dataset): def __init__(self, img_path, img_label, transform=None): self.img_path = img_path self.img_label = img_label if transform is not None: self.transform = transform else: self.transform = None def __getitem__(self, index): img = Image.open(self.img_path[index]).convert(&amp;#39;RGB&amp;#39;) if self.transform is not None: img = self.transform(img) # 原始SVHN中类别10为数字0 lbl = np.array(self.img_label[index], dtype=np.int) #  lbl = list(lbl) &#43; (5 - len(lbl)) * [10] # 将数字转成定长度（为5）的数字，其中空的地方补充为【10】，也就是0. return img, torch.from_numpy(np.array(lbl[:5])) def __len__(self): return len(self.img_path) train_path = glob.glob(&amp;#39;../input/train/*.png&amp;#39;) #返回所有匹配的文件路径列表 train_path.sort() #list.sort(cmp=None, key=None, reverse=False)，升序排列，跟train_json的文件排列一直起来。 train_json = json.load(open(&amp;#39;../input/train.json&amp;#39;)) train_label = [train_json[x][&amp;#39;label&amp;#39;] for x in train_json] train_loader = torch.utils.data.DataLoader( SVHNDataset(train_path, train_label, transforms.Compose([ transforms.Resize((64, 128)), transforms.ColorJitter(0.3, 0.3, 0.2), transforms.RandomRotation(5), transforms.ToTensor(), transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) ])), batch_size=10, # 每批样本个数 shuffle=False, # 是否打乱顺序 num_workers=10, # 读取的线程个数 ) for data in train_loader: break   在加入DataLoder后，数据按照批次获取，每批次调用Dataset读取单个样本进行拼接。此时data的格式为：
torch.Size([10, 3, 64, 128]), torch.Size([10, 6])
前者为图像文件，为batchsize * chanel * height * width次序；后者为字符标签。
torchvision.ToTensor() 源码如下：
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  class ToTensor(object): &amp;#34;&amp;#34;&amp;#34;Convert a ``PIL Image`` or ``numpy.ndarray`` to tensor. Converts a PIL Image or numpy.ndarray (H x W x C) in the range [0, 255] to a torch.FloatTensor of shape (C x H x W) in the range [0.0, 1.0]. &amp;#34;&amp;#34;&amp;#34; def __call__(self, pic): &amp;#34;&amp;#34;&amp;#34; Args: pic (PIL Image or numpy.ndarray): Image to be converted to tensor. Returns: Tensor: Converted image. &amp;#34;&amp;#34;&amp;#34; return F.to_tensor(pic) def __repr__(self): return self.__class__.__name__ &#43; &amp;#39;()&amp;#39;   ToTensor具体操作：
 转换维度：img = torch.from_numpy (pic.transpose ((2, 0, 1))) 转变数据类型 ：float/int divide 255: img.float().div(255)  Baseline结果 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20  Epoch: 0, Train loss: 3.503765054543813 Val loss: 3.48130961894989 Val Acc 0.356 Epoch: 1, Train loss: 2.2491484214464825 Val loss: 3.0459648995399475 Val Acc 0.4333 Epoch: 2, Train loss: 1.8961329097747803 Val loss: 2.837818443775177 Val Acc 0.476 Epoch: 3, Train loss: 1.6731903288364411 Val loss: 2.7689380412101747 Val Acc 0.4909 Epoch: 4, Train loss: 1.5381509892145793 Val loss: 2.758125602722168 Val Acc 0.4978 Epoch: 5, Train loss: 1.4285292768081028 Val loss: 2.600436863899231 Val Acc 0.5247 Epoch: 6, Train loss: 1.3249877935647965 Val loss: 2.595946876049042 Val Acc 0.5155 Epoch: 7, Train loss: 1.2398218791087467 Val loss: 2.5257772111892702 Val Acc 0.5396 Epoch: 8, Train loss: 1.1702964349587759 Val loss: 2.5723482842445375 Val Acc 0.5343 Epoch: 9, Train loss: 1.102836936334769 Val loss: 2.5777434706687927 Val Acc 0.5385   " /><meta name="keywords" content="Deep Learning, Medical Field, Artificial Intelligence" />






<meta name="generator" content="Hugo 0.66.0 with theme even" />


<link rel="canonical" href="https://Naruto-AI-WY.github.io/post/datawhale_cv2/" />
<link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
<link rel="manifest" href="/manifest.json">
<link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5">

<script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
<link href="/dist/even.c2a46f00.min.css" rel="stylesheet">



<meta property="og:title" content="数据读取与数据扩增" />
<meta property="og:description" content="图像读取
在Python中有很多库可以完成数据读取的操作，比较常见的有Pillow和OpenCV。
PyTorch载入图片后ToTensor解读（含PIL和OpenCV读取图片对比）
（1）Pillow
Pillow是Python图像处理函式库(PIL）的一个分支。Pillow提供了常见的图像读取和处理的操作，而且可以与ipython notebook无缝集成，是应用比较广泛的库。


1
2
3
4
5


from PIL import Image
# 导入Pillow库

# 读取图片
im =Image.open(cat.jpg&#39;)





1
2
3
4
5


from PIL import Image, ImageFilter
im = Image.open(&#39;cat.jpg&#39;)
# 应用模糊滤镜:
im2 = im.filter(ImageFilter.BLUR)
im2.save(&#39;blur.jpg&#39;, &#39;jpeg&#39;)





1
2
3
4
5


from PIL import Image
# 打开一个jpg图像文件，注意是当前路径:
im = Image.open(&#39;cat.jpg&#39;)
im.thumbnail((w//2, h//2))
im.save(&#39;thumbnail.jpg&#39;, &#39;jpeg&#39;)



Pillow的官方文档：https://pillow.readthedocs.io/en/stable/
（2）OpenCV
OpenCV是一个跨平台的计算机视觉库，最早由Intel开源得来。OpenCV发展的非常早，拥有众多的计算机视觉、数字图像处理和机器视觉等功能。OpenCV在功能上比Pillow更加强大很多，学习成本也高很多。


1
2
3
4
5


import cv2
# 导入Opencv库
img = cv2.imread(&#39;cat.jpg&#39;)
# Opencv默认颜色通道顺序是BRG，转换一下
img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)





1
2
3
4
5


import cv2
# 导入Opencv库
img = cv2.imread(&#39;cat.jpg&#39;)
img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
# 转换为灰度图





1
2
3
4
5
6
7
8


import cv2
# 导入Opencv库
img = cv2.imread(&#39;cat.jpg&#39;)
img =cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
# 转换为灰度图
# Canny边缘检测
edges = cv2.Canny(img, 30, 70)
cv2.imwrite(&#39;canny.jpg&#39;, edges)



OpenCV包含了众多的图像处理的功能，OpenCV包含了你能想得到的只要与图像相关的操作。此外OpenCV还内置了很多的图像特征处理算法，如关键点检测、边缘检测和直线检测等。
OpenCV官网：https://opencv.org/
OpenCV Github：https://github.com/opencv/opencv
OpenCV 扩展算法库：https://github.com/opencv/opencv_contrib
数据扩增方法
数据扩增介绍
在深度学习中数据扩增方法非常重要，数据扩增可以增加训练集的样本，同时也可以有效缓解模型过拟合的情况，也可以给模型带来的更强的泛化能力。

常见的数据扩增方法
在常见的数据扩增方法中，一般会从图像颜色、尺寸、形态、空间和像素等角度进行变换。当然不同的数据扩增方法可以自由进行组合，得到更加丰富的数据扩增方法。
以torchvision为例，常见的数据扩增方法包括：
transforms.CenterCrop 对图片中心进行裁剪
transforms.ColorJitter 对图像颜色的对比度、饱和度和零度进行变换
transforms.FiveCrop 对图像四个角和中心进行裁剪得到五分图像
transforms.Grayscale 对图像进行灰度变换
transforms.Pad 使用固定值进行像素填充
transforms.RandomAffine 随机仿射变换
transforms.RandomCrop 随机区域裁剪
transforms.RandomHorizontalFlip 随机水平翻转
transforms.RandomRotation 随机旋转
transforms.RandomVerticalFlip 随机垂直翻转

常用的数据扩增库


torchvision
https://github.com/pytorch/vision
pytorch官方提供的数据扩增库，提供了基本的数据数据扩增方法，可以无缝与torch进行集成；但数据扩增方法种类较少，且速度中等；


imgaug
https://github.com/aleju/imgaug
imgaug是常用的第三方数据扩增库，提供了多样的数据扩增方法，且组合起来非常方便，速度较快；


albumentations
https://albumentations.readthedocs.io
是常用的第三方数据扩增库，提供了多样的数据扩增方法，对图像分类、语义分割、物体检测和关键点检测都支持，速度较快。


Pytorch读取数据


 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57


import os, sys, glob, shutil, json
import cv2

from PIL import Image
import numpy as np

import torch
from torch.utils.data.dataset import Dataset
import torchvision.transforms as transforms

class SVHNDataset(Dataset):
    def __init__(self, img_path, img_label, transform=None):  # 重写Dataset的初始化方法，在初始化的时候将数据载入
        self.img_path = img_path
        self.img_label = img_label 
        if transform is not None:
            self.transform = transform
        else:
            self.transform = None

    def __getitem__(self, index): # 返回一行数据
        img = Image.open(self.img_path[index]).convert(&#39;RGB&#39;)

        if self.transform is not None:
            img = self.transform(img)
        
        # 原始SVHN中类别10为数字0
        lbl = np.array(self.img_label[index], dtype=np.int)
        lbl = list(lbl)  &#43; (5 - len(lbl)) * [10]
        
        return img, torch.from_numpy(np.array(lbl[:5]))

    def __len__(self):     #返回长度，数据总数
        return len(self.img_path)

train_path = glob.glob(&#39;../input/train/*.png&#39;)
train_path.sort()
train_json = json.load(open(&#39;../input/train.json&#39;))
train_label = [train_json[x][&#39;label&#39;] for x in train_json]

data = SVHNDataset(train_path, train_label,
          # Compose方法将几种变换组合起来
          transforms.Compose([
              # 缩放到固定尺寸
              transforms.Resize((64, 128)),

              # 随机颜色变换
              transforms.ColorJitter(0.2, 0.2, 0.2),

              # 加入随机旋转
              transforms.RandomRotation(5),

              # 将图片转换为pytorch 的tenstor，（C,H,W）的转换、PyTorch在做一般的深度学习图像处理任务时，先使用dataset类和dataloader类读入图片，在读入的时候需要做transform变换，其中transform一般都需要ToTensor()操作，将dataset类中__getitem__()方法内读入的PIL或CV的图像数据转换为torch.FloatTensor
              # transforms.ToTensor(),

              # 对图像像素进行归一化
              # transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])
            ]))



Dataset：对数据集的封装，提供索引方式的对数据样本进行读取
DataLoder：对Dataset进行封装，提供批量读取的迭代读取

详细可阅读下面的文章
PyTorch实现自由的数据读取


 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55


import os, sys, glob, shutil, json
import cv2

from PIL import Image
import numpy as np

import torch
from torch.utils.data.dataset import Dataset
import torchvision.transforms as transforms

class SVHNDataset(Dataset):
    def __init__(self, img_path, img_label, transform=None):
        self.img_path = img_path
        self.img_label = img_label 
        if transform is not None:
            self.transform = transform
        else:
            self.transform = None

    def __getitem__(self, index):
        img = Image.open(self.img_path[index]).convert(&#39;RGB&#39;)

        if self.transform is not None:
            img = self.transform(img)
        
        # 原始SVHN中类别10为数字0
        lbl = np.array(self.img_label[index], dtype=np.int) # 
        lbl = list(lbl)  &#43; (5 - len(lbl)) * [10]            # 将数字转成定长度（为5）的数字，其中空的地方补充为【10】，也就是0.
        
        return img, torch.from_numpy(np.array(lbl[:5]))

    def __len__(self):
        return len(self.img_path)

train_path = glob.glob(&#39;../input/train/*.png&#39;) #返回所有匹配的文件路径列表
train_path.sort()  #list.sort(cmp=None, key=None, reverse=False)，升序排列，跟train_json的文件排列一直起来。
train_json = json.load(open(&#39;../input/train.json&#39;))
train_label = [train_json[x][&#39;label&#39;] for x in train_json]

train_loader = torch.utils.data.DataLoader(
        SVHNDataset(train_path, train_label,
                   transforms.Compose([
                       transforms.Resize((64, 128)),
                       transforms.ColorJitter(0.3, 0.3, 0.2),
                       transforms.RandomRotation(5),
                       transforms.ToTensor(),
                       transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
            ])), 
    batch_size=10, # 每批样本个数
    shuffle=False, # 是否打乱顺序
    num_workers=10, # 读取的线程个数
)

for data in train_loader:
    break


在加入DataLoder后，数据按照批次获取，每批次调用Dataset读取单个样本进行拼接。此时data的格式为：
torch.Size([10, 3, 64, 128]), torch.Size([10, 6])
前者为图像文件，为batchsize * chanel * height * width次序；后者为字符标签。
torchvision.ToTensor()
源码如下：


 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17


class ToTensor(object):
    &#34;&#34;&#34;Convert a ``PIL Image`` or ``numpy.ndarray`` to tensor.
    Converts a PIL Image or numpy.ndarray (H x W x C) in the range
    [0, 255] to a torch.FloatTensor of shape (C x H x W) in the range [0.0, 1.0].
    &#34;&#34;&#34;

    def __call__(self, pic):
        &#34;&#34;&#34;
        Args:
            pic (PIL Image or numpy.ndarray): Image to be converted to tensor.
        Returns:
            Tensor: Converted image.
        &#34;&#34;&#34;
        return F.to_tensor(pic)

    def __repr__(self):
        return self.__class__.__name__ &#43; &#39;()&#39;


ToTensor具体操作：

转换维度：img = torch.from_numpy (pic.transpose ((2, 0, 1)))
转变数据类型 ：float/int
divide 255: img.float().div(255)

Baseline结果


 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
19
20


Epoch: 0, Train loss: 3.503765054543813      Val loss: 3.48130961894989
Val Acc 0.356
Epoch: 1, Train loss: 2.2491484214464825     Val loss: 3.0459648995399475
Val Acc 0.4333
Epoch: 2, Train loss: 1.8961329097747803     Val loss: 2.837818443775177
Val Acc 0.476
Epoch: 3, Train loss: 1.6731903288364411     Val loss: 2.7689380412101747
Val Acc 0.4909
Epoch: 4, Train loss: 1.5381509892145793     Val loss: 2.758125602722168
Val Acc 0.4978
Epoch: 5, Train loss: 1.4285292768081028     Val loss: 2.600436863899231
Val Acc 0.5247
Epoch: 6, Train loss: 1.3249877935647965     Val loss: 2.595946876049042
Val Acc 0.5155
Epoch: 7, Train loss: 1.2398218791087467     Val loss: 2.5257772111892702
Val Acc 0.5396
Epoch: 8, Train loss: 1.1702964349587759     Val loss: 2.5723482842445375
Val Acc 0.5343
Epoch: 9, Train loss: 1.102836936334769      Val loss: 2.5777434706687927
Val Acc 0.5385


" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://Naruto-AI-WY.github.io/post/datawhale_cv2/" />
<meta property="article:published_time" content="2020-05-23T21:34:11+08:00" />
<meta property="article:modified_time" content="2020-05-23T21:34:11+08:00" />
<meta itemprop="name" content="数据读取与数据扩增">
<meta itemprop="description" content="图像读取
在Python中有很多库可以完成数据读取的操作，比较常见的有Pillow和OpenCV。
PyTorch载入图片后ToTensor解读（含PIL和OpenCV读取图片对比）
（1）Pillow
Pillow是Python图像处理函式库(PIL）的一个分支。Pillow提供了常见的图像读取和处理的操作，而且可以与ipython notebook无缝集成，是应用比较广泛的库。


1
2
3
4
5


from PIL import Image
# 导入Pillow库

# 读取图片
im =Image.open(cat.jpg&#39;)





1
2
3
4
5


from PIL import Image, ImageFilter
im = Image.open(&#39;cat.jpg&#39;)
# 应用模糊滤镜:
im2 = im.filter(ImageFilter.BLUR)
im2.save(&#39;blur.jpg&#39;, &#39;jpeg&#39;)





1
2
3
4
5


from PIL import Image
# 打开一个jpg图像文件，注意是当前路径:
im = Image.open(&#39;cat.jpg&#39;)
im.thumbnail((w//2, h//2))
im.save(&#39;thumbnail.jpg&#39;, &#39;jpeg&#39;)



Pillow的官方文档：https://pillow.readthedocs.io/en/stable/
（2）OpenCV
OpenCV是一个跨平台的计算机视觉库，最早由Intel开源得来。OpenCV发展的非常早，拥有众多的计算机视觉、数字图像处理和机器视觉等功能。OpenCV在功能上比Pillow更加强大很多，学习成本也高很多。


1
2
3
4
5


import cv2
# 导入Opencv库
img = cv2.imread(&#39;cat.jpg&#39;)
# Opencv默认颜色通道顺序是BRG，转换一下
img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)





1
2
3
4
5


import cv2
# 导入Opencv库
img = cv2.imread(&#39;cat.jpg&#39;)
img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
# 转换为灰度图





1
2
3
4
5
6
7
8


import cv2
# 导入Opencv库
img = cv2.imread(&#39;cat.jpg&#39;)
img =cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
# 转换为灰度图
# Canny边缘检测
edges = cv2.Canny(img, 30, 70)
cv2.imwrite(&#39;canny.jpg&#39;, edges)



OpenCV包含了众多的图像处理的功能，OpenCV包含了你能想得到的只要与图像相关的操作。此外OpenCV还内置了很多的图像特征处理算法，如关键点检测、边缘检测和直线检测等。
OpenCV官网：https://opencv.org/
OpenCV Github：https://github.com/opencv/opencv
OpenCV 扩展算法库：https://github.com/opencv/opencv_contrib
数据扩增方法
数据扩增介绍
在深度学习中数据扩增方法非常重要，数据扩增可以增加训练集的样本，同时也可以有效缓解模型过拟合的情况，也可以给模型带来的更强的泛化能力。

常见的数据扩增方法
在常见的数据扩增方法中，一般会从图像颜色、尺寸、形态、空间和像素等角度进行变换。当然不同的数据扩增方法可以自由进行组合，得到更加丰富的数据扩增方法。
以torchvision为例，常见的数据扩增方法包括：
transforms.CenterCrop 对图片中心进行裁剪
transforms.ColorJitter 对图像颜色的对比度、饱和度和零度进行变换
transforms.FiveCrop 对图像四个角和中心进行裁剪得到五分图像
transforms.Grayscale 对图像进行灰度变换
transforms.Pad 使用固定值进行像素填充
transforms.RandomAffine 随机仿射变换
transforms.RandomCrop 随机区域裁剪
transforms.RandomHorizontalFlip 随机水平翻转
transforms.RandomRotation 随机旋转
transforms.RandomVerticalFlip 随机垂直翻转

常用的数据扩增库


torchvision
https://github.com/pytorch/vision
pytorch官方提供的数据扩增库，提供了基本的数据数据扩增方法，可以无缝与torch进行集成；但数据扩增方法种类较少，且速度中等；


imgaug
https://github.com/aleju/imgaug
imgaug是常用的第三方数据扩增库，提供了多样的数据扩增方法，且组合起来非常方便，速度较快；


albumentations
https://albumentations.readthedocs.io
是常用的第三方数据扩增库，提供了多样的数据扩增方法，对图像分类、语义分割、物体检测和关键点检测都支持，速度较快。


Pytorch读取数据


 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57


import os, sys, glob, shutil, json
import cv2

from PIL import Image
import numpy as np

import torch
from torch.utils.data.dataset import Dataset
import torchvision.transforms as transforms

class SVHNDataset(Dataset):
    def __init__(self, img_path, img_label, transform=None):  # 重写Dataset的初始化方法，在初始化的时候将数据载入
        self.img_path = img_path
        self.img_label = img_label 
        if transform is not None:
            self.transform = transform
        else:
            self.transform = None

    def __getitem__(self, index): # 返回一行数据
        img = Image.open(self.img_path[index]).convert(&#39;RGB&#39;)

        if self.transform is not None:
            img = self.transform(img)
        
        # 原始SVHN中类别10为数字0
        lbl = np.array(self.img_label[index], dtype=np.int)
        lbl = list(lbl)  &#43; (5 - len(lbl)) * [10]
        
        return img, torch.from_numpy(np.array(lbl[:5]))

    def __len__(self):     #返回长度，数据总数
        return len(self.img_path)

train_path = glob.glob(&#39;../input/train/*.png&#39;)
train_path.sort()
train_json = json.load(open(&#39;../input/train.json&#39;))
train_label = [train_json[x][&#39;label&#39;] for x in train_json]

data = SVHNDataset(train_path, train_label,
          # Compose方法将几种变换组合起来
          transforms.Compose([
              # 缩放到固定尺寸
              transforms.Resize((64, 128)),

              # 随机颜色变换
              transforms.ColorJitter(0.2, 0.2, 0.2),

              # 加入随机旋转
              transforms.RandomRotation(5),

              # 将图片转换为pytorch 的tenstor，（C,H,W）的转换、PyTorch在做一般的深度学习图像处理任务时，先使用dataset类和dataloader类读入图片，在读入的时候需要做transform变换，其中transform一般都需要ToTensor()操作，将dataset类中__getitem__()方法内读入的PIL或CV的图像数据转换为torch.FloatTensor
              # transforms.ToTensor(),

              # 对图像像素进行归一化
              # transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])
            ]))



Dataset：对数据集的封装，提供索引方式的对数据样本进行读取
DataLoder：对Dataset进行封装，提供批量读取的迭代读取

详细可阅读下面的文章
PyTorch实现自由的数据读取


 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55


import os, sys, glob, shutil, json
import cv2

from PIL import Image
import numpy as np

import torch
from torch.utils.data.dataset import Dataset
import torchvision.transforms as transforms

class SVHNDataset(Dataset):
    def __init__(self, img_path, img_label, transform=None):
        self.img_path = img_path
        self.img_label = img_label 
        if transform is not None:
            self.transform = transform
        else:
            self.transform = None

    def __getitem__(self, index):
        img = Image.open(self.img_path[index]).convert(&#39;RGB&#39;)

        if self.transform is not None:
            img = self.transform(img)
        
        # 原始SVHN中类别10为数字0
        lbl = np.array(self.img_label[index], dtype=np.int) # 
        lbl = list(lbl)  &#43; (5 - len(lbl)) * [10]            # 将数字转成定长度（为5）的数字，其中空的地方补充为【10】，也就是0.
        
        return img, torch.from_numpy(np.array(lbl[:5]))

    def __len__(self):
        return len(self.img_path)

train_path = glob.glob(&#39;../input/train/*.png&#39;) #返回所有匹配的文件路径列表
train_path.sort()  #list.sort(cmp=None, key=None, reverse=False)，升序排列，跟train_json的文件排列一直起来。
train_json = json.load(open(&#39;../input/train.json&#39;))
train_label = [train_json[x][&#39;label&#39;] for x in train_json]

train_loader = torch.utils.data.DataLoader(
        SVHNDataset(train_path, train_label,
                   transforms.Compose([
                       transforms.Resize((64, 128)),
                       transforms.ColorJitter(0.3, 0.3, 0.2),
                       transforms.RandomRotation(5),
                       transforms.ToTensor(),
                       transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
            ])), 
    batch_size=10, # 每批样本个数
    shuffle=False, # 是否打乱顺序
    num_workers=10, # 读取的线程个数
)

for data in train_loader:
    break


在加入DataLoder后，数据按照批次获取，每批次调用Dataset读取单个样本进行拼接。此时data的格式为：
torch.Size([10, 3, 64, 128]), torch.Size([10, 6])
前者为图像文件，为batchsize * chanel * height * width次序；后者为字符标签。
torchvision.ToTensor()
源码如下：


 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17


class ToTensor(object):
    &#34;&#34;&#34;Convert a ``PIL Image`` or ``numpy.ndarray`` to tensor.
    Converts a PIL Image or numpy.ndarray (H x W x C) in the range
    [0, 255] to a torch.FloatTensor of shape (C x H x W) in the range [0.0, 1.0].
    &#34;&#34;&#34;

    def __call__(self, pic):
        &#34;&#34;&#34;
        Args:
            pic (PIL Image or numpy.ndarray): Image to be converted to tensor.
        Returns:
            Tensor: Converted image.
        &#34;&#34;&#34;
        return F.to_tensor(pic)

    def __repr__(self):
        return self.__class__.__name__ &#43; &#39;()&#39;


ToTensor具体操作：

转换维度：img = torch.from_numpy (pic.transpose ((2, 0, 1)))
转变数据类型 ：float/int
divide 255: img.float().div(255)

Baseline结果


 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
19
20


Epoch: 0, Train loss: 3.503765054543813      Val loss: 3.48130961894989
Val Acc 0.356
Epoch: 1, Train loss: 2.2491484214464825     Val loss: 3.0459648995399475
Val Acc 0.4333
Epoch: 2, Train loss: 1.8961329097747803     Val loss: 2.837818443775177
Val Acc 0.476
Epoch: 3, Train loss: 1.6731903288364411     Val loss: 2.7689380412101747
Val Acc 0.4909
Epoch: 4, Train loss: 1.5381509892145793     Val loss: 2.758125602722168
Val Acc 0.4978
Epoch: 5, Train loss: 1.4285292768081028     Val loss: 2.600436863899231
Val Acc 0.5247
Epoch: 6, Train loss: 1.3249877935647965     Val loss: 2.595946876049042
Val Acc 0.5155
Epoch: 7, Train loss: 1.2398218791087467     Val loss: 2.5257772111892702
Val Acc 0.5396
Epoch: 8, Train loss: 1.1702964349587759     Val loss: 2.5723482842445375
Val Acc 0.5343
Epoch: 9, Train loss: 1.102836936334769      Val loss: 2.5777434706687927
Val Acc 0.5385


">
<meta itemprop="datePublished" content="2020-05-23T21:34:11&#43;08:00" />
<meta itemprop="dateModified" content="2020-05-23T21:34:11&#43;08:00" />
<meta itemprop="wordCount" content="2534">



<meta itemprop="keywords" content="" /><meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="数据读取与数据扩增"/>
<meta name="twitter:description" content="图像读取
在Python中有很多库可以完成数据读取的操作，比较常见的有Pillow和OpenCV。
PyTorch载入图片后ToTensor解读（含PIL和OpenCV读取图片对比）
（1）Pillow
Pillow是Python图像处理函式库(PIL）的一个分支。Pillow提供了常见的图像读取和处理的操作，而且可以与ipython notebook无缝集成，是应用比较广泛的库。


1
2
3
4
5


from PIL import Image
# 导入Pillow库

# 读取图片
im =Image.open(cat.jpg&#39;)





1
2
3
4
5


from PIL import Image, ImageFilter
im = Image.open(&#39;cat.jpg&#39;)
# 应用模糊滤镜:
im2 = im.filter(ImageFilter.BLUR)
im2.save(&#39;blur.jpg&#39;, &#39;jpeg&#39;)





1
2
3
4
5


from PIL import Image
# 打开一个jpg图像文件，注意是当前路径:
im = Image.open(&#39;cat.jpg&#39;)
im.thumbnail((w//2, h//2))
im.save(&#39;thumbnail.jpg&#39;, &#39;jpeg&#39;)



Pillow的官方文档：https://pillow.readthedocs.io/en/stable/
（2）OpenCV
OpenCV是一个跨平台的计算机视觉库，最早由Intel开源得来。OpenCV发展的非常早，拥有众多的计算机视觉、数字图像处理和机器视觉等功能。OpenCV在功能上比Pillow更加强大很多，学习成本也高很多。


1
2
3
4
5


import cv2
# 导入Opencv库
img = cv2.imread(&#39;cat.jpg&#39;)
# Opencv默认颜色通道顺序是BRG，转换一下
img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)





1
2
3
4
5


import cv2
# 导入Opencv库
img = cv2.imread(&#39;cat.jpg&#39;)
img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
# 转换为灰度图





1
2
3
4
5
6
7
8


import cv2
# 导入Opencv库
img = cv2.imread(&#39;cat.jpg&#39;)
img =cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
# 转换为灰度图
# Canny边缘检测
edges = cv2.Canny(img, 30, 70)
cv2.imwrite(&#39;canny.jpg&#39;, edges)



OpenCV包含了众多的图像处理的功能，OpenCV包含了你能想得到的只要与图像相关的操作。此外OpenCV还内置了很多的图像特征处理算法，如关键点检测、边缘检测和直线检测等。
OpenCV官网：https://opencv.org/
OpenCV Github：https://github.com/opencv/opencv
OpenCV 扩展算法库：https://github.com/opencv/opencv_contrib
数据扩增方法
数据扩增介绍
在深度学习中数据扩增方法非常重要，数据扩增可以增加训练集的样本，同时也可以有效缓解模型过拟合的情况，也可以给模型带来的更强的泛化能力。

常见的数据扩增方法
在常见的数据扩增方法中，一般会从图像颜色、尺寸、形态、空间和像素等角度进行变换。当然不同的数据扩增方法可以自由进行组合，得到更加丰富的数据扩增方法。
以torchvision为例，常见的数据扩增方法包括：
transforms.CenterCrop 对图片中心进行裁剪
transforms.ColorJitter 对图像颜色的对比度、饱和度和零度进行变换
transforms.FiveCrop 对图像四个角和中心进行裁剪得到五分图像
transforms.Grayscale 对图像进行灰度变换
transforms.Pad 使用固定值进行像素填充
transforms.RandomAffine 随机仿射变换
transforms.RandomCrop 随机区域裁剪
transforms.RandomHorizontalFlip 随机水平翻转
transforms.RandomRotation 随机旋转
transforms.RandomVerticalFlip 随机垂直翻转

常用的数据扩增库


torchvision
https://github.com/pytorch/vision
pytorch官方提供的数据扩增库，提供了基本的数据数据扩增方法，可以无缝与torch进行集成；但数据扩增方法种类较少，且速度中等；


imgaug
https://github.com/aleju/imgaug
imgaug是常用的第三方数据扩增库，提供了多样的数据扩增方法，且组合起来非常方便，速度较快；


albumentations
https://albumentations.readthedocs.io
是常用的第三方数据扩增库，提供了多样的数据扩增方法，对图像分类、语义分割、物体检测和关键点检测都支持，速度较快。


Pytorch读取数据


 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57


import os, sys, glob, shutil, json
import cv2

from PIL import Image
import numpy as np

import torch
from torch.utils.data.dataset import Dataset
import torchvision.transforms as transforms

class SVHNDataset(Dataset):
    def __init__(self, img_path, img_label, transform=None):  # 重写Dataset的初始化方法，在初始化的时候将数据载入
        self.img_path = img_path
        self.img_label = img_label 
        if transform is not None:
            self.transform = transform
        else:
            self.transform = None

    def __getitem__(self, index): # 返回一行数据
        img = Image.open(self.img_path[index]).convert(&#39;RGB&#39;)

        if self.transform is not None:
            img = self.transform(img)
        
        # 原始SVHN中类别10为数字0
        lbl = np.array(self.img_label[index], dtype=np.int)
        lbl = list(lbl)  &#43; (5 - len(lbl)) * [10]
        
        return img, torch.from_numpy(np.array(lbl[:5]))

    def __len__(self):     #返回长度，数据总数
        return len(self.img_path)

train_path = glob.glob(&#39;../input/train/*.png&#39;)
train_path.sort()
train_json = json.load(open(&#39;../input/train.json&#39;))
train_label = [train_json[x][&#39;label&#39;] for x in train_json]

data = SVHNDataset(train_path, train_label,
          # Compose方法将几种变换组合起来
          transforms.Compose([
              # 缩放到固定尺寸
              transforms.Resize((64, 128)),

              # 随机颜色变换
              transforms.ColorJitter(0.2, 0.2, 0.2),

              # 加入随机旋转
              transforms.RandomRotation(5),

              # 将图片转换为pytorch 的tenstor，（C,H,W）的转换、PyTorch在做一般的深度学习图像处理任务时，先使用dataset类和dataloader类读入图片，在读入的时候需要做transform变换，其中transform一般都需要ToTensor()操作，将dataset类中__getitem__()方法内读入的PIL或CV的图像数据转换为torch.FloatTensor
              # transforms.ToTensor(),

              # 对图像像素进行归一化
              # transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])
            ]))



Dataset：对数据集的封装，提供索引方式的对数据样本进行读取
DataLoder：对Dataset进行封装，提供批量读取的迭代读取

详细可阅读下面的文章
PyTorch实现自由的数据读取


 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55


import os, sys, glob, shutil, json
import cv2

from PIL import Image
import numpy as np

import torch
from torch.utils.data.dataset import Dataset
import torchvision.transforms as transforms

class SVHNDataset(Dataset):
    def __init__(self, img_path, img_label, transform=None):
        self.img_path = img_path
        self.img_label = img_label 
        if transform is not None:
            self.transform = transform
        else:
            self.transform = None

    def __getitem__(self, index):
        img = Image.open(self.img_path[index]).convert(&#39;RGB&#39;)

        if self.transform is not None:
            img = self.transform(img)
        
        # 原始SVHN中类别10为数字0
        lbl = np.array(self.img_label[index], dtype=np.int) # 
        lbl = list(lbl)  &#43; (5 - len(lbl)) * [10]            # 将数字转成定长度（为5）的数字，其中空的地方补充为【10】，也就是0.
        
        return img, torch.from_numpy(np.array(lbl[:5]))

    def __len__(self):
        return len(self.img_path)

train_path = glob.glob(&#39;../input/train/*.png&#39;) #返回所有匹配的文件路径列表
train_path.sort()  #list.sort(cmp=None, key=None, reverse=False)，升序排列，跟train_json的文件排列一直起来。
train_json = json.load(open(&#39;../input/train.json&#39;))
train_label = [train_json[x][&#39;label&#39;] for x in train_json]

train_loader = torch.utils.data.DataLoader(
        SVHNDataset(train_path, train_label,
                   transforms.Compose([
                       transforms.Resize((64, 128)),
                       transforms.ColorJitter(0.3, 0.3, 0.2),
                       transforms.RandomRotation(5),
                       transforms.ToTensor(),
                       transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
            ])), 
    batch_size=10, # 每批样本个数
    shuffle=False, # 是否打乱顺序
    num_workers=10, # 读取的线程个数
)

for data in train_loader:
    break


在加入DataLoder后，数据按照批次获取，每批次调用Dataset读取单个样本进行拼接。此时data的格式为：
torch.Size([10, 3, 64, 128]), torch.Size([10, 6])
前者为图像文件，为batchsize * chanel * height * width次序；后者为字符标签。
torchvision.ToTensor()
源码如下：


 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17


class ToTensor(object):
    &#34;&#34;&#34;Convert a ``PIL Image`` or ``numpy.ndarray`` to tensor.
    Converts a PIL Image or numpy.ndarray (H x W x C) in the range
    [0, 255] to a torch.FloatTensor of shape (C x H x W) in the range [0.0, 1.0].
    &#34;&#34;&#34;

    def __call__(self, pic):
        &#34;&#34;&#34;
        Args:
            pic (PIL Image or numpy.ndarray): Image to be converted to tensor.
        Returns:
            Tensor: Converted image.
        &#34;&#34;&#34;
        return F.to_tensor(pic)

    def __repr__(self):
        return self.__class__.__name__ &#43; &#39;()&#39;


ToTensor具体操作：

转换维度：img = torch.from_numpy (pic.transpose ((2, 0, 1)))
转变数据类型 ：float/int
divide 255: img.float().div(255)

Baseline结果


 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
19
20


Epoch: 0, Train loss: 3.503765054543813      Val loss: 3.48130961894989
Val Acc 0.356
Epoch: 1, Train loss: 2.2491484214464825     Val loss: 3.0459648995399475
Val Acc 0.4333
Epoch: 2, Train loss: 1.8961329097747803     Val loss: 2.837818443775177
Val Acc 0.476
Epoch: 3, Train loss: 1.6731903288364411     Val loss: 2.7689380412101747
Val Acc 0.4909
Epoch: 4, Train loss: 1.5381509892145793     Val loss: 2.758125602722168
Val Acc 0.4978
Epoch: 5, Train loss: 1.4285292768081028     Val loss: 2.600436863899231
Val Acc 0.5247
Epoch: 6, Train loss: 1.3249877935647965     Val loss: 2.595946876049042
Val Acc 0.5155
Epoch: 7, Train loss: 1.2398218791087467     Val loss: 2.5257772111892702
Val Acc 0.5396
Epoch: 8, Train loss: 1.1702964349587759     Val loss: 2.5723482842445375
Val Acc 0.5343
Epoch: 9, Train loss: 1.102836936334769      Val loss: 2.5777434706687927
Val Acc 0.5385


"/>

<!--[if lte IE 9]>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/classlist/1.1.20170427/classList.min.js"></script>
<![endif]-->

<!--[if lt IE 9]>
  <script src="https://cdn.jsdelivr.net/npm/html5shiv@3.7.3/dist/html5shiv.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/respond.js@1.4.2/dest/respond.min.js"></script>
<![endif]-->

</head>
<body>
  <div id="mobile-navbar" class="mobile-navbar">
  <div class="mobile-header-logo">
    <a href="/" class="logo">Artificial Intelligence</a>
  </div>
  <div class="mobile-navbar-icon">
    <span></span>
    <span></span>
    <span></span>
  </div>
</div>
<nav id="mobile-menu" class="mobile-menu slideout-menu">
  <ul class="mobile-menu-list">
    <a href="/">
        <li class="mobile-menu-item">首页</li>
      </a><a href="/post/">
        <li class="mobile-menu-item">档案</li>
      </a><a href="/tags/">
        <li class="mobile-menu-item">标签</li>
      </a><a href="/categories/">
        <li class="mobile-menu-item">分类</li>
      </a><a href="/about/">
        <li class="mobile-menu-item">About</li>
      </a>
  </ul>
</nav>
  <div class="container" id="mobile-panel">
    <header id="header" class="header">
        <div class="logo-wrapper">
  <a href="/" class="logo">Artificial Intelligence</a>
</div>

<nav class="site-navbar">
  <ul id="menu" class="menu">
    <li class="menu-item">
        <a class="menu-item-link" href="/">首页</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/post/">档案</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/tags/">标签</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/categories/">分类</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/about/">About</a>
      </li>
  </ul>
</nav>
    </header>

    <main id="main" class="main">
      <div class="content-wrapper">
        <div id="content" class="content">
          <article class="post">
    
    <header class="post-header">
      <h1 class="post-title">数据读取与数据扩增</h1>

      <div class="post-meta">
        <span class="post-time"> 2020-05-23 </span>
        
          <span class="more-meta"> 约 2534 字 </span>
          <span class="more-meta"> 预计阅读 6 分钟 </span>
        <span id="busuanzi_container_page_pv" class="more-meta"> <span id="busuanzi_value_page_pv"><img src="/img/spinner.svg" alt="spinner.svg"/></span> 次阅读 </span>
      </div>
    </header>

    
    <div class="post-content">
      <h2 id="图像读取">图像读取</h2>
<p>在Python中有很多库可以完成数据读取的操作，比较常见的有Pillow和OpenCV。<br>
<a href="https://www.cnblogs.com/ocean1100/p/9494640.html">PyTorch载入图片后ToTensor解读（含PIL和OpenCV读取图片对比）</a></p>
<h3 id="1pillow">（1）Pillow</h3>
<p>Pillow是Python图像处理函式库(PIL）的一个分支。Pillow提供了常见的图像读取和处理的操作，而且可以与ipython notebook无缝集成，是应用比较广泛的库。</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-python" data-lang="python"><span class="kn">from</span> <span class="nn">PIL</span> <span class="kn">import</span> <span class="n">Image</span>
<span class="c1"># 导入Pillow库</span>

<span class="c1"># 读取图片</span>
<span class="n">im</span> <span class="o">=</span><span class="n">Image</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="n">cat</span><span class="o">.</span><span class="n">jpg</span><span class="s1">&#39;)</span>
</code></pre></td></tr></table>
</div>
</div><p><img src="/img/cat.png" alt="CV3"></p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-python" data-lang="python"><span class="kn">from</span> <span class="nn">PIL</span> <span class="kn">import</span> <span class="n">Image</span><span class="p">,</span> <span class="n">ImageFilter</span>
<span class="n">im</span> <span class="o">=</span> <span class="n">Image</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="s1">&#39;cat.jpg&#39;</span><span class="p">)</span>
<span class="c1"># 应用模糊滤镜:</span>
<span class="n">im2</span> <span class="o">=</span> <span class="n">im</span><span class="o">.</span><span class="n">filter</span><span class="p">(</span><span class="n">ImageFilter</span><span class="o">.</span><span class="n">BLUR</span><span class="p">)</span>
<span class="n">im2</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s1">&#39;blur.jpg&#39;</span><span class="p">,</span> <span class="s1">&#39;jpeg&#39;</span><span class="p">)</span>
</code></pre></td></tr></table>
</div>
</div><p><img src="/img/cat1.png" alt="CV3"></p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-python" data-lang="python"><span class="kn">from</span> <span class="nn">PIL</span> <span class="kn">import</span> <span class="n">Image</span>
<span class="c1"># 打开一个jpg图像文件，注意是当前路径:</span>
<span class="n">im</span> <span class="o">=</span> <span class="n">Image</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="s1">&#39;cat.jpg&#39;</span><span class="p">)</span>
<span class="n">im</span><span class="o">.</span><span class="n">thumbnail</span><span class="p">((</span><span class="n">w</span><span class="o">//</span><span class="mi">2</span><span class="p">,</span> <span class="n">h</span><span class="o">//</span><span class="mi">2</span><span class="p">))</span>
<span class="n">im</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s1">&#39;thumbnail.jpg&#39;</span><span class="p">,</span> <span class="s1">&#39;jpeg&#39;</span><span class="p">)</span>
</code></pre></td></tr></table>
</div>
</div><p><img src="/img/cat3.png" alt="CV3"></p>
<p>Pillow的官方文档：https://pillow.readthedocs.io/en/stable/</p>
<h3 id="2opencv">（2）OpenCV</h3>
<p>OpenCV是一个跨平台的计算机视觉库，最早由Intel开源得来。OpenCV发展的非常早，拥有众多的计算机视觉、数字图像处理和机器视觉等功能。OpenCV在功能上比Pillow更加强大很多，学习成本也高很多。</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">cv2</span>
<span class="c1"># 导入Opencv库</span>
<span class="n">img</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">imread</span><span class="p">(</span><span class="s1">&#39;cat.jpg&#39;</span><span class="p">)</span>
<span class="c1"># Opencv默认颜色通道顺序是BRG，转换一下</span>
<span class="n">img</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">cvtColor</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">cv2</span><span class="o">.</span><span class="n">COLOR_BGR2RGB</span><span class="p">)</span>
</code></pre></td></tr></table>
</div>
</div><p><img src="/img/cat.png" alt="CV3"></p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">cv2</span>
<span class="c1"># 导入Opencv库</span>
<span class="n">img</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">imread</span><span class="p">(</span><span class="s1">&#39;cat.jpg&#39;</span><span class="p">)</span>
<span class="n">img</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">cvtColor</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">cv2</span><span class="o">.</span><span class="n">COLOR_BGR2GRAY</span><span class="p">)</span>
<span class="c1"># 转换为灰度图</span>
</code></pre></td></tr></table>
</div>
</div><p><img src="/img/cat2.png" alt="CV3"></p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span><span class="lnt">8
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">cv2</span>
<span class="c1"># 导入Opencv库</span>
<span class="n">img</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">imread</span><span class="p">(</span><span class="s1">&#39;cat.jpg&#39;</span><span class="p">)</span>
<span class="n">img</span> <span class="o">=</span><span class="n">cv2</span><span class="o">.</span><span class="n">cvtColor</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">cv2</span><span class="o">.</span><span class="n">COLOR_BGR2GRAY</span><span class="p">)</span>
<span class="c1"># 转换为灰度图</span>
<span class="c1"># Canny边缘检测</span>
<span class="n">edges</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">Canny</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="mi">30</span><span class="p">,</span> <span class="mi">70</span><span class="p">)</span>
<span class="n">cv2</span><span class="o">.</span><span class="n">imwrite</span><span class="p">(</span><span class="s1">&#39;canny.jpg&#39;</span><span class="p">,</span> <span class="n">edges</span><span class="p">)</span>
</code></pre></td></tr></table>
</div>
</div><p><img src="/img/cat4.png" alt="CV3"></p>
<p>OpenCV包含了众多的图像处理的功能，OpenCV包含了你能想得到的只要与图像相关的操作。此外OpenCV还内置了很多的图像特征处理算法，如关键点检测、边缘检测和直线检测等。<br>
OpenCV官网：https://opencv.org/<br>
OpenCV Github：https://github.com/opencv/opencv<br>
OpenCV 扩展算法库：https://github.com/opencv/opencv_contrib</p>
<h2 id="数据扩增方法">数据扩增方法</h2>
<h3 id="数据扩增介绍">数据扩增介绍</h3>
<p>在深度学习中数据扩增方法非常重要，数据扩增可以增加训练集的样本，同时也可以有效缓解模型过拟合的情况，也可以给模型带来的更强的泛化能力。</p>
<p><img src="/img/cat_enlarge.png" alt="CV3"></p>
<h3 id="常见的数据扩增方法">常见的数据扩增方法</h3>
<p>在常见的数据扩增方法中，一般会从图像颜色、尺寸、形态、空间和像素等角度进行变换。当然不同的数据扩增方法可以自由进行组合，得到更加丰富的数据扩增方法。</p>
<p>以torchvision为例，常见的数据扩增方法包括：</p>
<p>transforms.CenterCrop 对图片中心进行裁剪<br>
transforms.ColorJitter 对图像颜色的对比度、饱和度和零度进行变换<br>
transforms.FiveCrop 对图像四个角和中心进行裁剪得到五分图像<br>
transforms.Grayscale 对图像进行灰度变换<br>
transforms.Pad 使用固定值进行像素填充<br>
transforms.RandomAffine 随机仿射变换<br>
transforms.RandomCrop 随机区域裁剪<br>
transforms.RandomHorizontalFlip 随机水平翻转<br>
transforms.RandomRotation 随机旋转<br>
transforms.RandomVerticalFlip 随机垂直翻转</p>
<p><img src="/img/enlarge.png" alt="CV3"></p>
<h3 id="常用的数据扩增库">常用的数据扩增库</h3>
<ul>
<li>
<p>torchvision<br>
<a href="https://github.com/pytorch/vision">https://github.com/pytorch/vision</a><br>
pytorch官方提供的数据扩增库，提供了基本的数据数据扩增方法，可以无缝与torch进行集成；但数据扩增方法种类较少，且速度中等；</p>
</li>
<li>
<p>imgaug<br>
<a href="https://github.com/aleju/imgaug">https://github.com/aleju/imgaug</a><br>
imgaug是常用的第三方数据扩增库，提供了多样的数据扩增方法，且组合起来非常方便，速度较快；</p>
</li>
<li>
<p>albumentations<br>
<a href="https://albumentations.readthedocs.io">https://albumentations.readthedocs.io</a><br>
是常用的第三方数据扩增库，提供了多样的数据扩增方法，对图像分类、语义分割、物体检测和关键点检测都支持，速度较快。</p>
</li>
</ul>
<h2 id="pytorch读取数据">Pytorch读取数据</h2>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span><span class="lnt">31
</span><span class="lnt">32
</span><span class="lnt">33
</span><span class="lnt">34
</span><span class="lnt">35
</span><span class="lnt">36
</span><span class="lnt">37
</span><span class="lnt">38
</span><span class="lnt">39
</span><span class="lnt">40
</span><span class="lnt">41
</span><span class="lnt">42
</span><span class="lnt">43
</span><span class="lnt">44
</span><span class="lnt">45
</span><span class="lnt">46
</span><span class="lnt">47
</span><span class="lnt">48
</span><span class="lnt">49
</span><span class="lnt">50
</span><span class="lnt">51
</span><span class="lnt">52
</span><span class="lnt">53
</span><span class="lnt">54
</span><span class="lnt">55
</span><span class="lnt">56
</span><span class="lnt">57
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">os</span><span class="o">,</span> <span class="nn">sys</span><span class="o">,</span> <span class="nn">glob</span><span class="o">,</span> <span class="nn">shutil</span><span class="o">,</span> <span class="nn">json</span>
<span class="kn">import</span> <span class="nn">cv2</span>

<span class="kn">from</span> <span class="nn">PIL</span> <span class="kn">import</span> <span class="n">Image</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>

<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">torch.utils.data.dataset</span> <span class="kn">import</span> <span class="n">Dataset</span>
<span class="kn">import</span> <span class="nn">torchvision.transforms</span> <span class="kn">as</span> <span class="nn">transforms</span>

<span class="k">class</span> <span class="nc">SVHNDataset</span><span class="p">(</span><span class="n">Dataset</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">img_path</span><span class="p">,</span> <span class="n">img_label</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>  <span class="c1"># 重写Dataset的初始化方法，在初始化的时候将数据载入</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">img_path</span> <span class="o">=</span> <span class="n">img_path</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">img_label</span> <span class="o">=</span> <span class="n">img_label</span> 
        <span class="k">if</span> <span class="n">transform</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">transform</span> <span class="o">=</span> <span class="n">transform</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">transform</span> <span class="o">=</span> <span class="bp">None</span>

    <span class="k">def</span> <span class="fm">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">index</span><span class="p">):</span> <span class="c1"># 返回一行数据</span>
        <span class="n">img</span> <span class="o">=</span> <span class="n">Image</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">img_path</span><span class="p">[</span><span class="n">index</span><span class="p">])</span><span class="o">.</span><span class="n">convert</span><span class="p">(</span><span class="s1">&#39;RGB&#39;</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">transform</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
            <span class="n">img</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">img</span><span class="p">)</span>
        
        <span class="c1"># 原始SVHN中类别10为数字0</span>
        <span class="n">lbl</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">img_label</span><span class="p">[</span><span class="n">index</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int</span><span class="p">)</span>
        <span class="n">lbl</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">lbl</span><span class="p">)</span>  <span class="o">+</span> <span class="p">(</span><span class="mi">5</span> <span class="o">-</span> <span class="nb">len</span><span class="p">(</span><span class="n">lbl</span><span class="p">))</span> <span class="o">*</span> <span class="p">[</span><span class="mi">10</span><span class="p">]</span>
        
        <span class="k">return</span> <span class="n">img</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">lbl</span><span class="p">[:</span><span class="mi">5</span><span class="p">]))</span>

    <span class="k">def</span> <span class="fm">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>     <span class="c1">#返回长度，数据总数</span>
        <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">img_path</span><span class="p">)</span>

<span class="n">train_path</span> <span class="o">=</span> <span class="n">glob</span><span class="o">.</span><span class="n">glob</span><span class="p">(</span><span class="s1">&#39;../input/train/*.png&#39;</span><span class="p">)</span>
<span class="n">train_path</span><span class="o">.</span><span class="n">sort</span><span class="p">()</span>
<span class="n">train_json</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="nb">open</span><span class="p">(</span><span class="s1">&#39;../input/train.json&#39;</span><span class="p">))</span>
<span class="n">train_label</span> <span class="o">=</span> <span class="p">[</span><span class="n">train_json</span><span class="p">[</span><span class="n">x</span><span class="p">][</span><span class="s1">&#39;label&#39;</span><span class="p">]</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">train_json</span><span class="p">]</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">SVHNDataset</span><span class="p">(</span><span class="n">train_path</span><span class="p">,</span> <span class="n">train_label</span><span class="p">,</span>
          <span class="c1"># Compose方法将几种变换组合起来</span>
          <span class="n">transforms</span><span class="o">.</span><span class="n">Compose</span><span class="p">([</span>
              <span class="c1"># 缩放到固定尺寸</span>
              <span class="n">transforms</span><span class="o">.</span><span class="n">Resize</span><span class="p">((</span><span class="mi">64</span><span class="p">,</span> <span class="mi">128</span><span class="p">)),</span>

              <span class="c1"># 随机颜色变换</span>
              <span class="n">transforms</span><span class="o">.</span><span class="n">ColorJitter</span><span class="p">(</span><span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">),</span>

              <span class="c1"># 加入随机旋转</span>
              <span class="n">transforms</span><span class="o">.</span><span class="n">RandomRotation</span><span class="p">(</span><span class="mi">5</span><span class="p">),</span>

              <span class="c1"># 将图片转换为pytorch 的tenstor，（C,H,W）的转换、PyTorch在做一般的深度学习图像处理任务时，先使用dataset类和dataloader类读入图片，在读入的时候需要做transform变换，其中transform一般都需要ToTensor()操作，将dataset类中__getitem__()方法内读入的PIL或CV的图像数据转换为torch.FloatTensor</span>
              <span class="c1"># transforms.ToTensor(),</span>

              <span class="c1"># 对图像像素进行归一化</span>
              <span class="c1"># transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])</span>
            <span class="p">]))</span>
</code></pre></td></tr></table>
</div>
</div><ul>
<li>Dataset：对数据集的封装，提供索引方式的对数据样本进行读取</li>
<li>DataLoder：对Dataset进行封装，提供批量读取的迭代读取</li>
</ul>
<p>详细可阅读下面的文章<br>
<a href="https://zhuanlan.zhihu.com/p/30385675">PyTorch实现自由的数据读取</a></p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span><span class="lnt">31
</span><span class="lnt">32
</span><span class="lnt">33
</span><span class="lnt">34
</span><span class="lnt">35
</span><span class="lnt">36
</span><span class="lnt">37
</span><span class="lnt">38
</span><span class="lnt">39
</span><span class="lnt">40
</span><span class="lnt">41
</span><span class="lnt">42
</span><span class="lnt">43
</span><span class="lnt">44
</span><span class="lnt">45
</span><span class="lnt">46
</span><span class="lnt">47
</span><span class="lnt">48
</span><span class="lnt">49
</span><span class="lnt">50
</span><span class="lnt">51
</span><span class="lnt">52
</span><span class="lnt">53
</span><span class="lnt">54
</span><span class="lnt">55
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">os</span><span class="o">,</span> <span class="nn">sys</span><span class="o">,</span> <span class="nn">glob</span><span class="o">,</span> <span class="nn">shutil</span><span class="o">,</span> <span class="nn">json</span>
<span class="kn">import</span> <span class="nn">cv2</span>

<span class="kn">from</span> <span class="nn">PIL</span> <span class="kn">import</span> <span class="n">Image</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>

<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">torch.utils.data.dataset</span> <span class="kn">import</span> <span class="n">Dataset</span>
<span class="kn">import</span> <span class="nn">torchvision.transforms</span> <span class="kn">as</span> <span class="nn">transforms</span>

<span class="k">class</span> <span class="nc">SVHNDataset</span><span class="p">(</span><span class="n">Dataset</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">img_path</span><span class="p">,</span> <span class="n">img_label</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">img_path</span> <span class="o">=</span> <span class="n">img_path</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">img_label</span> <span class="o">=</span> <span class="n">img_label</span> 
        <span class="k">if</span> <span class="n">transform</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">transform</span> <span class="o">=</span> <span class="n">transform</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">transform</span> <span class="o">=</span> <span class="bp">None</span>

    <span class="k">def</span> <span class="fm">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">index</span><span class="p">):</span>
        <span class="n">img</span> <span class="o">=</span> <span class="n">Image</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">img_path</span><span class="p">[</span><span class="n">index</span><span class="p">])</span><span class="o">.</span><span class="n">convert</span><span class="p">(</span><span class="s1">&#39;RGB&#39;</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">transform</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
            <span class="n">img</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">img</span><span class="p">)</span>
        
        <span class="c1"># 原始SVHN中类别10为数字0</span>
        <span class="n">lbl</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">img_label</span><span class="p">[</span><span class="n">index</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int</span><span class="p">)</span> <span class="c1"># </span>
        <span class="n">lbl</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">lbl</span><span class="p">)</span>  <span class="o">+</span> <span class="p">(</span><span class="mi">5</span> <span class="o">-</span> <span class="nb">len</span><span class="p">(</span><span class="n">lbl</span><span class="p">))</span> <span class="o">*</span> <span class="p">[</span><span class="mi">10</span><span class="p">]</span>            <span class="c1"># 将数字转成定长度（为5）的数字，其中空的地方补充为【10】，也就是0.</span>
        
        <span class="k">return</span> <span class="n">img</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">lbl</span><span class="p">[:</span><span class="mi">5</span><span class="p">]))</span>

    <span class="k">def</span> <span class="fm">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">img_path</span><span class="p">)</span>

<span class="n">train_path</span> <span class="o">=</span> <span class="n">glob</span><span class="o">.</span><span class="n">glob</span><span class="p">(</span><span class="s1">&#39;../input/train/*.png&#39;</span><span class="p">)</span> <span class="c1">#返回所有匹配的文件路径列表</span>
<span class="n">train_path</span><span class="o">.</span><span class="n">sort</span><span class="p">()</span>  <span class="c1">#list.sort(cmp=None, key=None, reverse=False)，升序排列，跟train_json的文件排列一直起来。</span>
<span class="n">train_json</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="nb">open</span><span class="p">(</span><span class="s1">&#39;../input/train.json&#39;</span><span class="p">))</span>
<span class="n">train_label</span> <span class="o">=</span> <span class="p">[</span><span class="n">train_json</span><span class="p">[</span><span class="n">x</span><span class="p">][</span><span class="s1">&#39;label&#39;</span><span class="p">]</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">train_json</span><span class="p">]</span>

<span class="n">train_loader</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span>
        <span class="n">SVHNDataset</span><span class="p">(</span><span class="n">train_path</span><span class="p">,</span> <span class="n">train_label</span><span class="p">,</span>
                   <span class="n">transforms</span><span class="o">.</span><span class="n">Compose</span><span class="p">([</span>
                       <span class="n">transforms</span><span class="o">.</span><span class="n">Resize</span><span class="p">((</span><span class="mi">64</span><span class="p">,</span> <span class="mi">128</span><span class="p">)),</span>
                       <span class="n">transforms</span><span class="o">.</span><span class="n">ColorJitter</span><span class="p">(</span><span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">),</span>
                       <span class="n">transforms</span><span class="o">.</span><span class="n">RandomRotation</span><span class="p">(</span><span class="mi">5</span><span class="p">),</span>
                       <span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">(),</span>
                       <span class="n">transforms</span><span class="o">.</span><span class="n">Normalize</span><span class="p">([</span><span class="mf">0.485</span><span class="p">,</span> <span class="mf">0.456</span><span class="p">,</span> <span class="mf">0.406</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.229</span><span class="p">,</span> <span class="mf">0.224</span><span class="p">,</span> <span class="mf">0.225</span><span class="p">])</span>
            <span class="p">])),</span> 
    <span class="n">batch_size</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="c1"># 每批样本个数</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="c1"># 是否打乱顺序</span>
    <span class="n">num_workers</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="c1"># 读取的线程个数</span>
<span class="p">)</span>

<span class="k">for</span> <span class="n">data</span> <span class="ow">in</span> <span class="n">train_loader</span><span class="p">:</span>
    <span class="k">break</span>
</code></pre></td></tr></table>
</div>
</div><p>在加入DataLoder后，数据按照批次获取，每批次调用Dataset读取单个样本进行拼接。此时data的格式为：<br>
torch.Size([10, 3, 64, 128]), torch.Size([10, 6])<br>
前者为图像文件，为batchsize * chanel * height * width次序；后者为字符标签。</p>
<h3 id="torchvisiontotensor">torchvision.ToTensor()</h3>
<p>源码如下：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-python" data-lang="python"><span class="k">class</span> <span class="nc">ToTensor</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
    <span class="s2">&#34;&#34;&#34;Convert a ``PIL Image`` or ``numpy.ndarray`` to tensor.
</span><span class="s2">    Converts a PIL Image or numpy.ndarray (H x W x C) in the range
</span><span class="s2">    [0, 255] to a torch.FloatTensor of shape (C x H x W) in the range [0.0, 1.0].
</span><span class="s2">    &#34;&#34;&#34;</span>

    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">pic</span><span class="p">):</span>
        <span class="s2">&#34;&#34;&#34;
</span><span class="s2">        Args:
</span><span class="s2">            pic (PIL Image or numpy.ndarray): Image to be converted to tensor.
</span><span class="s2">        Returns:
</span><span class="s2">            Tensor: Converted image.
</span><span class="s2">        &#34;&#34;&#34;</span>
        <span class="k">return</span> <span class="n">F</span><span class="o">.</span><span class="n">to_tensor</span><span class="p">(</span><span class="n">pic</span><span class="p">)</span>

    <span class="k">def</span> <span class="fm">__repr__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span> <span class="o">+</span> <span class="s1">&#39;()&#39;</span>
</code></pre></td></tr></table>
</div>
</div><p>ToTensor具体操作：</p>
<ul>
<li>转换维度：img = torch.from_numpy (pic.transpose ((2, 0, 1)))</li>
<li>转变数据类型 ：float/int</li>
<li>divide 255: img.float().div(255)</li>
</ul>
<h3 id="baseline结果">Baseline结果</h3>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-python" data-lang="python"><span class="n">Epoch</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span> <span class="n">Train</span> <span class="n">loss</span><span class="p">:</span> <span class="mf">3.503765054543813</span>      <span class="n">Val</span> <span class="n">loss</span><span class="p">:</span> <span class="mf">3.48130961894989</span>
<span class="n">Val</span> <span class="n">Acc</span> <span class="mf">0.356</span>
<span class="n">Epoch</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span> <span class="n">Train</span> <span class="n">loss</span><span class="p">:</span> <span class="mf">2.2491484214464825</span>     <span class="n">Val</span> <span class="n">loss</span><span class="p">:</span> <span class="mf">3.0459648995399475</span>
<span class="n">Val</span> <span class="n">Acc</span> <span class="mf">0.4333</span>
<span class="n">Epoch</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span> <span class="n">Train</span> <span class="n">loss</span><span class="p">:</span> <span class="mf">1.8961329097747803</span>     <span class="n">Val</span> <span class="n">loss</span><span class="p">:</span> <span class="mf">2.837818443775177</span>
<span class="n">Val</span> <span class="n">Acc</span> <span class="mf">0.476</span>
<span class="n">Epoch</span><span class="p">:</span> <span class="mi">3</span><span class="p">,</span> <span class="n">Train</span> <span class="n">loss</span><span class="p">:</span> <span class="mf">1.6731903288364411</span>     <span class="n">Val</span> <span class="n">loss</span><span class="p">:</span> <span class="mf">2.7689380412101747</span>
<span class="n">Val</span> <span class="n">Acc</span> <span class="mf">0.4909</span>
<span class="n">Epoch</span><span class="p">:</span> <span class="mi">4</span><span class="p">,</span> <span class="n">Train</span> <span class="n">loss</span><span class="p">:</span> <span class="mf">1.5381509892145793</span>     <span class="n">Val</span> <span class="n">loss</span><span class="p">:</span> <span class="mf">2.758125602722168</span>
<span class="n">Val</span> <span class="n">Acc</span> <span class="mf">0.4978</span>
<span class="n">Epoch</span><span class="p">:</span> <span class="mi">5</span><span class="p">,</span> <span class="n">Train</span> <span class="n">loss</span><span class="p">:</span> <span class="mf">1.4285292768081028</span>     <span class="n">Val</span> <span class="n">loss</span><span class="p">:</span> <span class="mf">2.600436863899231</span>
<span class="n">Val</span> <span class="n">Acc</span> <span class="mf">0.5247</span>
<span class="n">Epoch</span><span class="p">:</span> <span class="mi">6</span><span class="p">,</span> <span class="n">Train</span> <span class="n">loss</span><span class="p">:</span> <span class="mf">1.3249877935647965</span>     <span class="n">Val</span> <span class="n">loss</span><span class="p">:</span> <span class="mf">2.595946876049042</span>
<span class="n">Val</span> <span class="n">Acc</span> <span class="mf">0.5155</span>
<span class="n">Epoch</span><span class="p">:</span> <span class="mi">7</span><span class="p">,</span> <span class="n">Train</span> <span class="n">loss</span><span class="p">:</span> <span class="mf">1.2398218791087467</span>     <span class="n">Val</span> <span class="n">loss</span><span class="p">:</span> <span class="mf">2.5257772111892702</span>
<span class="n">Val</span> <span class="n">Acc</span> <span class="mf">0.5396</span>
<span class="n">Epoch</span><span class="p">:</span> <span class="mi">8</span><span class="p">,</span> <span class="n">Train</span> <span class="n">loss</span><span class="p">:</span> <span class="mf">1.1702964349587759</span>     <span class="n">Val</span> <span class="n">loss</span><span class="p">:</span> <span class="mf">2.5723482842445375</span>
<span class="n">Val</span> <span class="n">Acc</span> <span class="mf">0.5343</span>
<span class="n">Epoch</span><span class="p">:</span> <span class="mi">9</span><span class="p">,</span> <span class="n">Train</span> <span class="n">loss</span><span class="p">:</span> <span class="mf">1.102836936334769</span>      <span class="n">Val</span> <span class="n">loss</span><span class="p">:</span> <span class="mf">2.5777434706687927</span>
<span class="n">Val</span> <span class="n">Acc</span> <span class="mf">0.5385</span>
</code></pre></td></tr></table>
</div>
</div><!-- raw HTML omitted -->
    </div>

    
<footer class="post-footer">
      
      <nav class="post-nav">
        
        <a class="next" href="/post/datawhale_cv/">
            <span class="next-text nav-default">Datawhale 零基础入门CV赛事-Task1 赛题理解</span>
            <span class="next-text nav-mobile">下一篇</span>
            <i class="iconfont icon-right"></i>
          </a>
      </nav>
    </footer>
  </article>
        </div>
        

  <span id="/post/datawhale_cv2/" class="leancloud_visitors" data-flag-title="数据读取与数据扩增">
		<span class="post-meta-item-text">文章阅读量 </span>
		<span class="leancloud-visitors-count">0</span>
		<p></p>
	  </span>
  <div id="vcomments"></div>
  <script src="//cdn1.lncld.net/static/js/3.0.4/av-min.js"></script>
  <script src='//unpkg.com/valine/dist/Valine.min.js'></script>
  <script type="text/javascript">
    new Valine({
        el: '#vcomments' ,
        appId: '7Lh11XDaA9fG1uq7PARExRro-gzGzoHsz',
        appKey: 'ujEJbIQ8kR84JOqTEzEpDJdX',
        notify:  false ,
        verify:  false ,
        avatar:'mm',
        placeholder: '说点什么吧...',
        visitor:  true 
    });
  </script>

  

      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="social-links">
      <a href="mailto:187342084@qq.com" class="iconfont icon-email" title="email"></a>
      <a href="http://localhost:1313" class="iconfont icon-stack-overflow" title="stack-overflow"></a>
      <a href="http://localhost:1313" class="iconfont icon-twitter" title="twitter"></a>
      <a href="http://localhost:1313" class="iconfont icon-facebook" title="facebook"></a>
      <a href="http://localhost:1313" class="iconfont icon-linkedin" title="linkedin"></a>
      <a href="http://localhost:1313" class="iconfont icon-google" title="google"></a>
      <a href="http://localhost:1313" class="iconfont icon-github" title="github"></a>
      <a href="http://localhost:1313" class="iconfont icon-weibo" title="weibo"></a>
      <a href="http://localhost:1313" class="iconfont icon-zhihu" title="zhihu"></a>
      <a href="http://localhost:1313" class="iconfont icon-douban" title="douban"></a>
      <a href="http://localhost:1313" class="iconfont icon-pocket" title="pocket"></a>
      <a href="http://localhost:1313" class="iconfont icon-tumblr" title="tumblr"></a>
      <a href="http://localhost:1313" class="iconfont icon-instagram" title="instagram"></a>
      <a href="http://localhost:1313" class="iconfont icon-gitlab" title="gitlab"></a>
      <a href="http://localhost:1313" class="iconfont icon-bilibili" title="bilibili"></a>
  <a href="https://Naruto-AI-WY.github.io/index.xml" type="application/rss+xml" class="iconfont icon-rss" title="rss"></a>
</div>

<div class="copyright">
  <span class="power-by">
    由 <a class="hexo-link" href="https://gohugo.io">Hugo</a> 强力驱动
  </span>
  <span class="division">|</span>
  <span class="theme-info">
    主题 - 
    <a class="theme-link" href="https://github.com/olOwOlo/hugo-theme-even">Even</a>
  </span>

  <div class="busuanzi-footer">
    <span id="busuanzi_container_site_pv"> 本站总访问量 <span id="busuanzi_value_site_pv"><img src="/img/spinner.svg" alt="spinner.svg"/></span> 次 </span>
      <span class="division">|</span>
    <span id="busuanzi_container_site_uv"> 本站总访客数 <span id="busuanzi_value_site_uv"><img src="/img/spinner.svg" alt="spinner.svg"/></span> 人 </span>
  </div>

  <span class="copyright-year">
    &copy; 
    2020
    <span class="heart">
      <i class="iconfont icon-heart"></i>
    </span>
    <span class="author">Naruto</span>
  </span>
</div>
    </footer>

    <div class="back-to-top" id="back-to-top">
      <i class="iconfont icon-up"></i>
    </div>
  </div>
  
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.2.1/dist/jquery.min.js" integrity="sha256-hwg4gsxgFZhOsEEamdOYGBf13FyQuiTwlAQgxVSNgt4=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/slideout@1.0.1/dist/slideout.min.js" integrity="sha256-t+zJ/g8/KXIJMjSVQdnibt4dlaDxc9zXr/9oNPeWqdg=" crossorigin="anonymous"></script>
  
<script type="text/javascript" src="/dist/even.26188efa.min.js"></script>



<script id="baidu_push">
  (function(){
    if (window.location.hostname === 'localhost') return;
    var bp = document.createElement('script'); bp.async = true;
    var curProtocol = window.location.protocol.split(':')[0];
    if (curProtocol === 'https') {
      bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
    }
    else {
      bp.src = 'http://push.zhanzhang.baidu.com/push.js';
    }
    var s = document.getElementsByTagName("script")[0];
    s.parentNode.insertBefore(bp, s);
  })();
</script>




</body>
</html>
